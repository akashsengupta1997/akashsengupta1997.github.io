<!DOCTYPE HTML>
<html style="background-color:black; color:white;" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akash Sengupta</title>
  
  <meta name="author" content="Akash Sengupta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/University_Crest.png">
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PB26JZTCNC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-PB26JZTCNC');
  </script>
  
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akash Sengupta</name>
              </p>
              <p>
                I am a fourth year PhD student in the Computer Vision Group at the University of Cambridge,
                supervised by <a href="https://mi.eng.cam.ac.uk/~cipolla/">Prof. Roberto Cipolla</a> and <a href="http://mi.eng.cam.ac.uk/~ib255/">Dr. Ignas Budvytis</a>.
              </p>
              <p>
                My research interests lie in 3D reconstruction of complex, dynamic objects - such as humans.
                I am also broadly interested in probabilistic machine learning and generative modelling, and work towards adapting models from these fields to 3D reconstruction
                from 2D observations. This is a fundamentally ill-posed problem, thus motivating a probabilistic approach.
              </p>
              <p>
                Prior to my PhD, I obtained an MEng in Information Engineering from the University of Cambridge.
                As a student, I have been fortunate to be an intern at <a href="https://cambridgequantum.com">Cambridge Quantum</a>,
                <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge/"> Microsoft Mixed Reality & AI</a>
                and <a href="https://research.google/locations/zurich/"> Google Research</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:as2562@cam.ac.uk">Email</a> &nbsp/&nbsp
                <a href="https://github.com/akashsengupta1997">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/AkashSengupta97">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=zccA54AAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akash-sengupta-854426185/">LinkedIn </a> &nbsp/&nbsp
                <a href="data/Akash_Sengupta_CV_short.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/akash.png"><img style="width:60%;max-width:60%" alt="profile photo" src="images/akash.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->

        <h2>News</h2>
        <ul>
          <li><b>February 2024</b>: My internship at Google Zurich ended with a CVPR 2024 publication: DiffHuman!</li>
          <li><b>February 2023</b>: HuManiFlow was accepted to CVPR 2023! Paper and code are now public - see below.</li>
        </ul>

        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <a href="images/cvpr2024.mp4"><video autoplay loop muted playsinline src="images/cvpr2024.mp4" style="border-style: none" width="300"></video></a>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans</papertitle>
                <br>
                <strong>Akash Sengupta</strong>,
                <a href="https://research.google/people/thiemo-alldieck/">Thiemo Alldieck</a>,
                <a href="https://www.nikoskolot.com/">Nikos Kolotouros </a>,
                <a href="https://enriccorona.github.io/">Enric Corona </a>,
                <a href="https://scholar.google.es/citations?user=8lmzWycAAAAJ/">Andrei Zanfir </a>,
                <a href="https://research.google/people/cristian-sminchisescu/">Cristian Sminchisescu </a>

                <br>
                <em>CVPR 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2404.00485">Paper</a> &nbsp/&nbsp
                <a href="https://akashsengupta1997.github.io/diffhuman/">Project Page</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/watch?v=C6PeP0ciyAo">Video</a>
                <br>
                <p>
                  DiffHuman is a probabilistic method for photorealistic 3D human reconstruction from a single image.
                  Despite the ill-posed nature of this problem, most current methods are deterministic and output a single solution,
                  often resulting in a lack of geometric detail and blurriness in unseen or uncertain regions.
                  We predict a distribution over 3D reconstructions conditioned on an input 2D image,
                  which allows us to sample multiple input-consistent 3D solutions.
                  These often exhibit greater geometric and colour-wise detail than deterministic methods, especially in unseen/uncertain regions.
                </p>
              </td>
            </tr>

          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
<!--                <a href="images/cvpr2023.gif"><img src="images/cvpr2023.gif" alt="cvpr2023gif" style="border-style: none" width="300"></a>-->
                <a href="images/cvpr2023.mp4"><video autoplay loop muted playsinline src="images/cvpr2023.mp4" style="border-style: none" width="300"></video></a>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>HuManiFlow: Ancestor-Conditioned Normalising Flows on SO(3) Manifolds for Human Pose and Shape Distribution Estimation</papertitle>
                <br>
                <strong>Akash Sengupta</strong>,
                <a href="http://mi.eng.cam.ac.uk/~ib255/">Ignas Budvytis</a>,
                <a href="https://mi.eng.cam.ac.uk/~cipolla/">Roberto Cipolla</a>
                <br>
                <em>CVPR 2023</em>
                <br>
                <a href="https://arxiv.org/abs/2305.06968">Paper</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/watch?v=6xDiJNzPYNI">Video</a> &nbsp/&nbsp
                <a href="data/cvpr2023_poster.pdf">Poster</a> &nbsp/&nbsp
                <a href="https://github.com/akashsengupta1997/HuManiFlow">Code</a>
                <br>
                <p>
                  Probabilistic approaches to 3D human pose and shape estimation exhibit a trade-off between:
                  (i) 2D sample-input <em>consistency</em>, (ii) 3D sample <em>diversity</em> and (iii) distribution <em>accuracy</em>.
                  We predict simultaneously consistent, diverse and accurate distributions by using normalising flows over SO(3), the Lie group of per-body-part poses,
                  and by exploiting the human kinematic tree. This improves performance in downstream tasks, such as model-fitting with an image-conditioned prior.
                </p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/iccv2021.gif"><img src="images/iccv2021.gif" alt="iccv2021gif" style="border-style: none" width="320"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Hierarchical Kinematic Probability Distributions for 3D Human Shape and Pose Estimation from Images in the Wild</papertitle>
              <br>
              <strong>Akash Sengupta</strong>,
              <a href="http://mi.eng.cam.ac.uk/~ib255/">Ignas Budvytis</a>,
              <a href="https://mi.eng.cam.ac.uk/~cipolla/">Roberto Cipolla</a>
              <br>
              <em>ICCV 2021</em>
              <br>
              <a href="https://arxiv.org/abs/2110.00990">Paper</a> &nbsp/&nbsp
              <a href="https://www.youtube.com/watch?v=w7k9UC3sfGA">Video</a> &nbsp/&nbsp
              <a href="data/iccv2021_poster.pdf">Poster</a> &nbsp/&nbsp
              <a href="https://github.com/akashsengupta1997/HierarchicalProbabilistic3DHuman">Code</a>
              <br>
              <p>
                3D human pose and shape estimation from a single image is an ill-posed problem, since multiple 3D solutions can explain a 2D image.
                Thus, we estimate a hierarchical matrix-Fisher probability distribution over body pose conditioned on the observed image.
                This allows us to sample any number of plausible 3D solutions, and quantify body-part-specific prediction uncertainty.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/bmvc2021.gif"><img src="images/bmvc2021.gif" alt="bmvc2021gif" style="border-style: none" width="320"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Probabilistic Estimation of 3D Human Shape and Pose with a Semantic Local Parametric Model</papertitle>
              <br>
              <strong>Akash Sengupta</strong>,
              <a href="http://mi.eng.cam.ac.uk/~ib255/">Ignas Budvytis</a>,
              <a href="https://mi.eng.cam.ac.uk/~cipolla/">Roberto Cipolla</a>
              <br>
              <em>BMVC 2021</em>
              <br>
              <a href="https://arxiv.org/abs/2111.15404">Paper</a>
              <br>
              <p>
                Shape parameters in widely-used body models control global deformations over the whole body surface. Predicting probability distributions
                over <em> global </em> shape parameters does not meaningfully capture <em>local</em> and <em>directional</em> shape prediction uncertainty,
                e.g. due to camera angles or local occlusions. We present a simple mapping from local body measurements to global shape parameters,
                and use this to lift distributions over measurements to locally-uncertain distributions over body shape.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/cvpr2021.gif"><img src="images/cvpr2021.gif" alt="cvpr2021gif" style="border-style: none" width="320"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Probabilistic 3D Human Shape and Pose Estimation from Multiple Unconstrained Images in the Wild</papertitle>
              <br>
              <strong>Akash Sengupta</strong>,
              <a href="http://mi.eng.cam.ac.uk/~ib255/">Ignas Budvytis</a>,
              <a href="https://mi.eng.cam.ac.uk/~cipolla/">Roberto Cipolla</a>
              <br>
              <em>CVPR 2021</em>
              <br>
              <a href="https://arxiv.org/abs/2103.10978">Paper</a> &nbsp/&nbsp
              <a href="https://www.youtube.com/watch?v=0mX-9sSrlIU">Video</a> &nbsp/&nbsp
              <a href="data/cvpr2021_poster.pdf">Poster</a>
              <br>
              <p>
                We aim to estimate body shape from a set of multiple images of a subject, without constraints on body pose,
                camera viewpoint, or background conditions between images. We demonstrate that previous approaches
                result in inaccurate or inconsistent shape estimates. Our method predicts a distribution over
                body shape parameters conditioned on each image, which are probabilistically combined to obtain a consistent multi-image shape estimate.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bmvc2020.jpg" alt="bmvc2020" style="border-style: none" width="300">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Synthetic Training for Accurate 3D Human Pose and Shape Estimation in the Wild</papertitle>
              <br>
              <strong>Akash Sengupta</strong>,
              <a href="http://mi.eng.cam.ac.uk/~ib255/">Ignas Budvytis</a>,
              <a href="https://mi.eng.cam.ac.uk/~cipolla/">Roberto Cipolla</a>
              <br>
              <em>BMVC 2020</em>
              <br>
              <a href="https://arxiv.org/abs/2009.10013">Paper</a> &nbsp/&nbsp
              <a href="https://github.com/akashsengupta1997/STRAPS-3DHumanShapePose">Code</a> &nbsp/&nbsp
              <a href="https://github.com/akashsengupta1997/SSP-3D">Data</a>
              <br>
              <p>
                Deep-learning-based 3D human pose and shape estimators often predict inaccurate body shapes, due to a lack of <em>diverse</em> training data
                with <em>accurate</em> shape labels. We propose an on-the-fly synthetic data pipeline to mitigate data scarcity.
                In addition, we present an evaluation dataset for body shape estimation, SSP-3D, which consists of images of athletes
                with a variety of body shapes paired with pseudo-ground-truth 3D shape and pose labels.
              </p>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>

  <br>
  Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the website template.
</body>

</html>
